{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6418441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seisbench.data as sbd\n",
    "import seisbench.generate as sbg\n",
    "import seisbench.models as sbm\n",
    "from seisbench.util import worker_seeding\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "from seisnet.dataloaders import random_dataloader\n",
    "from seisnet.utils import get_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3632a880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CPU\n"
     ]
    }
   ],
   "source": [
    "model = sbm.PhaseNet(phases=\"PSN\", norm=\"peak\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    print(\"Running on GPU\")\n",
    "else:\n",
    "    print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94e91347",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, dev_loader = random_dataloader(f\"{get_data_dir()}/train_npz\",sample_size=100, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "688edc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "epochs = 500\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def loss_fn(y_pred, y_true, eps=1e-5):\n",
    "    # vector cross entropy loss\n",
    "    h = y_true * torch.log(y_pred + eps)\n",
    "    h = h.mean(-1).sum(-1)  # Mean along sample dimension and sum along pick dimension\n",
    "    h = h.mean()  # Mean over batch axis\n",
    "    return -h\n",
    "\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "def train_loop(dataloader):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    epoch_loss = 0\n",
    "    for batch_id, batch in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(batch[\"X\"].to(model.device))\n",
    "        loss = loss_fn(pred, batch[\"y\"].to(model.device))\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.detach().item()\n",
    "\n",
    "        if batch_id % 5 == 0:\n",
    "            loss, current = loss.item(), batch_id * batch[\"X\"].shape[0]\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    epoch_loss /= num_batches\n",
    "    train_loss.append(epoch_loss)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def test_loop(dataloader):\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    model.eval()  # close the model for evaluation\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            pred = model(batch[\"X\"].to(model.device))\n",
    "            test_loss += loss_fn(pred, batch[\"y\"].to(model.device)).item()\n",
    "\n",
    "    model.train()  # re-open model for training stage\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    val_loss.append(test_loss)\n",
    "    print(f\"Test avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e1b2cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.937903  [    0/   75]\n",
      "Test avg loss: 0.790637 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.713625  [    0/   75]\n",
      "Test avg loss: 0.696412 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.561300  [    0/   75]\n",
      "Test avg loss: 0.569454 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.422595  [    0/   75]\n",
      "Test avg loss: 0.543117 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.323247  [    0/   75]\n",
      "Test avg loss: 0.446341 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.242210  [    0/   75]\n",
      "Test avg loss: 0.350449 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.181113  [    0/   75]\n",
      "Test avg loss: 0.244159 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.150212  [    0/   75]\n",
      "Test avg loss: 0.166451 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.113452  [    0/   75]\n",
      "Test avg loss: 0.157492 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.100868  [    0/   75]\n",
      "Test avg loss: 0.132591 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.092573  [    0/   75]\n",
      "Test avg loss: 0.114191 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.087326  [    0/   75]\n",
      "Test avg loss: 0.127343 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.079836  [    0/   75]\n",
      "Test avg loss: 0.105217 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.075330  [    0/   75]\n",
      "Test avg loss: 0.112166 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.074633  [    0/   75]\n",
      "Test avg loss: 0.133438 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.073682  [    0/   75]\n",
      "Test avg loss: 0.101782 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.070284  [    0/   75]\n",
      "Test avg loss: 0.102029 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.065696  [    0/   75]\n",
      "Test avg loss: 0.103581 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.065755  [    0/   75]\n",
      "Test avg loss: 0.120508 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.067699  [    0/   75]\n",
      "Test avg loss: 0.118323 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.063961  [    0/   75]\n",
      "Test avg loss: 0.096268 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.064837  [    0/   75]\n",
      "Test avg loss: 0.103323 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.066116  [    0/   75]\n",
      "Test avg loss: 0.108722 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.062082  [    0/   75]\n",
      "Test avg loss: 0.111715 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.065091  [    0/   75]\n",
      "Test avg loss: 0.115735 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.058516  [    0/   75]\n",
      "Test avg loss: 0.095612 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.058946  [    0/   75]\n",
      "Test avg loss: 0.095569 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.057988  [    0/   75]\n",
      "Test avg loss: 0.101046 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.058497  [    0/   75]\n",
      "Test avg loss: 0.088442 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.056499  [    0/   75]\n",
      "Test avg loss: 0.112122 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.057885  [    0/   75]\n",
      "Test avg loss: 0.103528 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.056639  [    0/   75]\n",
      "Test avg loss: 0.100416 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.053336  [    0/   75]\n",
      "Test avg loss: 0.103275 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.051646  [    0/   75]\n",
      "Test avg loss: 0.096606 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.050445  [    0/   75]\n",
      "Test avg loss: 0.105808 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.051006  [    0/   75]\n",
      "Test avg loss: 0.109023 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.049821  [    0/   75]\n",
      "Test avg loss: 0.103767 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.047268  [    0/   75]\n",
      "Test avg loss: 0.103917 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.046922  [    0/   75]\n",
      "Test avg loss: 0.110908 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.046486  [    0/   75]\n",
      "Test avg loss: 0.094698 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.042973  [    0/   75]\n",
      "Test avg loss: 0.095421 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.044141  [    0/   75]\n",
      "Test avg loss: 0.081215 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.043502  [    0/   75]\n",
      "Test avg loss: 0.099558 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.042408  [    0/   75]\n",
      "Test avg loss: 0.087733 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.040424  [    0/   75]\n",
      "Test avg loss: 0.101650 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.039538  [    0/   75]\n",
      "Test avg loss: 0.096795 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.039262  [    0/   75]\n",
      "Test avg loss: 0.097146 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.038700  [    0/   75]\n",
      "Test avg loss: 0.090323 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.035116  [    0/   75]\n",
      "Test avg loss: 0.096699 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.034964  [    0/   75]\n",
      "Test avg loss: 0.092122 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.034831  [    0/   75]\n",
      "Test avg loss: 0.074162 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.035233  [    0/   75]\n",
      "Test avg loss: 0.083433 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.034304  [    0/   75]\n",
      "Test avg loss: 0.085161 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.032339  [    0/   75]\n",
      "Test avg loss: 0.094395 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.033882  [    0/   75]\n",
      "Test avg loss: 0.087719 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.032841  [    0/   75]\n",
      "Test avg loss: 0.077311 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.033515  [    0/   75]\n",
      "Test avg loss: 0.083559 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.032961  [    0/   75]\n",
      "Test avg loss: 0.097906 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.033372  [    0/   75]\n",
      "Test avg loss: 0.091109 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.032705  [    0/   75]\n",
      "Test avg loss: 0.073761 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.033518  [    0/   75]\n",
      "Test avg loss: 0.088597 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.032954  [    0/   75]\n",
      "Test avg loss: 0.095942 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.031410  [    0/   75]\n",
      "Test avg loss: 0.092574 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.032107  [    0/   75]\n",
      "Test avg loss: 0.074550 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.032415  [    0/   75]\n",
      "Test avg loss: 0.087230 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.031397  [    0/   75]\n",
      "Test avg loss: 0.083732 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.032854  [    0/   75]\n",
      "Test avg loss: 0.082976 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.032149  [    0/   75]\n",
      "Test avg loss: 0.098856 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.032750  [    0/   75]\n",
      "Test avg loss: 0.103111 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.033159  [    0/   75]\n",
      "Test avg loss: 0.099433 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.031421  [    0/   75]\n",
      "Test avg loss: 0.088433 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.030566  [    0/   75]\n",
      "Test avg loss: 0.101518 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.031517  [    0/   75]\n",
      "Test avg loss: 0.101696 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.032373  [    0/   75]\n",
      "Test avg loss: 0.081081 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.030966  [    0/   75]\n",
      "Test avg loss: 0.102434 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.031809  [    0/   75]\n",
      "Test avg loss: 0.102057 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.029619  [    0/   75]\n",
      "Test avg loss: 0.084764 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.032371  [    0/   75]\n",
      "Test avg loss: 0.087182 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.033306  [    0/   75]\n",
      "Test avg loss: 0.089086 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.032131  [    0/   75]\n",
      "Test avg loss: 0.101662 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.033213  [    0/   75]\n",
      "Test avg loss: 0.092906 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.033089  [    0/   75]\n",
      "Test avg loss: 0.082946 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.030761  [    0/   75]\n",
      "Test avg loss: 0.088586 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.032307  [    0/   75]\n",
      "Test avg loss: 0.090955 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.031315  [    0/   75]\n",
      "Test avg loss: 0.091749 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.030819  [    0/   75]\n",
      "Test avg loss: 0.095325 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.031825  [    0/   75]\n",
      "Test avg loss: 0.096155 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.031950  [    0/   75]\n",
      "Test avg loss: 0.070182 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.032099  [    0/   75]\n",
      "Test avg loss: 0.078636 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.031053  [    0/   75]\n",
      "Test avg loss: 0.080639 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.030457  [    0/   75]\n",
      "Test avg loss: 0.078592 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.031539  [    0/   75]\n",
      "Test avg loss: 0.082295 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.031457  [    0/   75]\n",
      "Test avg loss: 0.083234 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.031300  [    0/   75]\n",
      "Test avg loss: 0.103128 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.031150  [    0/   75]\n",
      "Test avg loss: 0.085424 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.031475  [    0/   75]\n",
      "Test avg loss: 0.084004 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.031900  [    0/   75]\n",
      "Test avg loss: 0.076413 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.031437  [    0/   75]\n",
      "Test avg loss: 0.083559 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.030358  [    0/   75]\n",
      "Test avg loss: 0.089871 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.031552  [    0/   75]\n",
      "Test avg loss: 0.081142 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.031564  [    0/   75]\n",
      "Test avg loss: 0.078277 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.031427  [    0/   75]\n",
      "Test avg loss: 0.101127 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.029198  [    0/   75]\n",
      "Test avg loss: 0.094328 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.030626  [    0/   75]\n",
      "Test avg loss: 0.091322 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.031475  [    0/   75]\n",
      "Test avg loss: 0.096787 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.029792  [    0/   75]\n",
      "Test avg loss: 0.096930 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.031003  [    0/   75]\n",
      "Test avg loss: 0.110382 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.031885  [    0/   75]\n",
      "Test avg loss: 0.095419 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.029443  [    0/   75]\n",
      "Test avg loss: 0.106255 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.030854  [    0/   75]\n",
      "Test avg loss: 0.077494 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.031100  [    0/   75]\n",
      "Test avg loss: 0.090327 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.031284  [    0/   75]\n",
      "Test avg loss: 0.089600 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.029678  [    0/   75]\n",
      "Test avg loss: 0.099313 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.031560  [    0/   75]\n",
      "Test avg loss: 0.093779 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.031010  [    0/   75]\n",
      "Test avg loss: 0.114416 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.030395  [    0/   75]\n",
      "Test avg loss: 0.092356 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.030632  [    0/   75]\n",
      "Test avg loss: 0.096297 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.031253  [    0/   75]\n",
      "Test avg loss: 0.099261 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.030648  [    0/   75]\n",
      "Test avg loss: 0.105332 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.030932  [    0/   75]\n",
      "Test avg loss: 0.113144 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.030881  [    0/   75]\n",
      "Test avg loss: 0.096839 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.029022  [    0/   75]\n",
      "Test avg loss: 0.082073 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.031473  [    0/   75]\n",
      "Test avg loss: 0.071533 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.030474  [    0/   75]\n",
      "Test avg loss: 0.094137 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.029288  [    0/   75]\n",
      "Test avg loss: 0.075794 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.031469  [    0/   75]\n",
      "Test avg loss: 0.107210 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.031035  [    0/   75]\n",
      "Test avg loss: 0.085617 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.029946  [    0/   75]\n",
      "Test avg loss: 0.082035 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.031041  [    0/   75]\n",
      "Test avg loss: 0.079093 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.030797  [    0/   75]\n",
      "Test avg loss: 0.105231 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.031236  [    0/   75]\n",
      "Test avg loss: 0.093204 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.031267  [    0/   75]\n",
      "Test avg loss: 0.087889 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.030013  [    0/   75]\n",
      "Test avg loss: 0.098553 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.028558  [    0/   75]\n",
      "Test avg loss: 0.096118 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.031054  [    0/   75]\n",
      "Test avg loss: 0.105993 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.030555  [    0/   75]\n",
      "Test avg loss: 0.099477 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.031332  [    0/   75]\n",
      "Test avg loss: 0.097560 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.030080  [    0/   75]\n",
      "Test avg loss: 0.120207 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.031470  [    0/   75]\n",
      "Test avg loss: 0.087181 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.030773  [    0/   75]\n",
      "Test avg loss: 0.113553 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.030122  [    0/   75]\n",
      "Test avg loss: 0.098807 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.030861  [    0/   75]\n",
      "Test avg loss: 0.077100 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.029922  [    0/   75]\n",
      "Test avg loss: 0.084157 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.031221  [    0/   75]\n",
      "Test avg loss: 0.095642 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.030733  [    0/   75]\n",
      "Test avg loss: 0.081797 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.030888  [    0/   75]\n",
      "Test avg loss: 0.112841 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.030088  [    0/   75]\n",
      "Test avg loss: 0.079056 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.029826  [    0/   75]\n",
      "Test avg loss: 0.082453 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.030711  [    0/   75]\n",
      "Test avg loss: 0.093776 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.029967  [    0/   75]\n",
      "Test avg loss: 0.097598 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.030237  [    0/   75]\n",
      "Test avg loss: 0.104951 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.030785  [    0/   75]\n",
      "Test avg loss: 0.091713 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.030769  [    0/   75]\n",
      "Test avg loss: 0.088181 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.030992  [    0/   75]\n",
      "Test avg loss: 0.116317 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.031339  [    0/   75]\n",
      "Test avg loss: 0.094267 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.030652  [    0/   75]\n",
      "Test avg loss: 0.112039 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.030778  [    0/   75]\n",
      "Test avg loss: 0.071857 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.029974  [    0/   75]\n",
      "Test avg loss: 0.098849 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.030466  [    0/   75]\n",
      "Test avg loss: 0.095236 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.029292  [    0/   75]\n",
      "Test avg loss: 0.106813 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.030885  [    0/   75]\n",
      "Test avg loss: 0.077325 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.030539  [    0/   75]\n",
      "Test avg loss: 0.088659 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.030933  [    0/   75]\n",
      "Test avg loss: 0.090211 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.028952  [    0/   75]\n",
      "Test avg loss: 0.080315 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.030265  [    0/   75]\n",
      "Test avg loss: 0.100279 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.030364  [    0/   75]\n",
      "Test avg loss: 0.079090 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.028699  [    0/   75]\n",
      "Test avg loss: 0.095088 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.030946  [    0/   75]\n",
      "Test avg loss: 0.075643 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.030348  [    0/   75]\n",
      "Test avg loss: 0.081756 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.030549  [    0/   75]\n",
      "Test avg loss: 0.103613 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.030730  [    0/   75]\n",
      "Test avg loss: 0.102422 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.029969  [    0/   75]\n",
      "Test avg loss: 0.081672 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.031070  [    0/   75]\n",
      "Test avg loss: 0.097473 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.030572  [    0/   75]\n",
      "Test avg loss: 0.085504 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.029346  [    0/   75]\n",
      "Test avg loss: 0.077678 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.030894  [    0/   75]\n",
      "Test avg loss: 0.074671 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.030720  [    0/   75]\n",
      "Test avg loss: 0.109210 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.030989  [    0/   75]\n",
      "Test avg loss: 0.087908 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.030506  [    0/   75]\n",
      "Test avg loss: 0.113753 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.031203  [    0/   75]\n",
      "Test avg loss: 0.074699 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.030843  [    0/   75]\n",
      "Test avg loss: 0.116036 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.029413  [    0/   75]\n",
      "Test avg loss: 0.111698 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.030943  [    0/   75]\n",
      "Test avg loss: 0.111375 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.030983  [    0/   75]\n",
      "Test avg loss: 0.081587 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.030215  [    0/   75]\n",
      "Test avg loss: 0.080430 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.031270  [    0/   75]\n",
      "Test avg loss: 0.101292 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.029319  [    0/   75]\n",
      "Test avg loss: 0.103639 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.030256  [    0/   75]\n",
      "Test avg loss: 0.082678 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.031116  [    0/   75]\n",
      "Test avg loss: 0.080474 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.029294  [    0/   75]\n",
      "Test avg loss: 0.092947 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.030679  [    0/   75]\n",
      "Test avg loss: 0.084935 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.029427  [    0/   75]\n",
      "Test avg loss: 0.099496 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.029451  [    0/   75]\n",
      "Test avg loss: 0.074590 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.031180  [    0/   75]\n",
      "Test avg loss: 0.076372 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.030932  [    0/   75]\n",
      "Test avg loss: 0.102196 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.030511  [    0/   75]\n",
      "Test avg loss: 0.083861 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.028694  [    0/   75]\n",
      "Test avg loss: 0.092236 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.030733  [    0/   75]\n",
      "Test avg loss: 0.099792 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.031455  [    0/   75]\n",
      "Test avg loss: 0.096048 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.031729  [    0/   75]\n",
      "Test avg loss: 0.083816 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.031180  [    0/   75]\n",
      "Test avg loss: 0.125057 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.031341  [    0/   75]\n",
      "Test avg loss: 0.090928 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.028832  [    0/   75]\n",
      "Test avg loss: 0.126867 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.030442  [    0/   75]\n",
      "Test avg loss: 0.079587 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.030989  [    0/   75]\n",
      "Test avg loss: 0.083405 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.029522  [    0/   75]\n",
      "Test avg loss: 0.093972 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.031045  [    0/   75]\n",
      "Test avg loss: 0.073714 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.030709  [    0/   75]\n",
      "Test avg loss: 0.103538 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.031371  [    0/   75]\n",
      "Test avg loss: 0.099471 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.030361  [    0/   75]\n",
      "Test avg loss: 0.109342 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.029425  [    0/   75]\n",
      "Test avg loss: 0.090040 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.030168  [    0/   75]\n",
      "Test avg loss: 0.083870 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.031611  [    0/   75]\n",
      "Test avg loss: 0.084116 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.031346  [    0/   75]\n",
      "Test avg loss: 0.118165 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.030941  [    0/   75]\n",
      "Test avg loss: 0.101469 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.028542  [    0/   75]\n",
      "Test avg loss: 0.081195 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.029791  [    0/   75]\n",
      "Test avg loss: 0.088777 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.030756  [    0/   75]\n",
      "Test avg loss: 0.107762 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.031403  [    0/   75]\n",
      "Test avg loss: 0.075962 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.031343  [    0/   75]\n",
      "Test avg loss: 0.080604 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.030406  [    0/   75]\n",
      "Test avg loss: 0.098207 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.030724  [    0/   75]\n",
      "Test avg loss: 0.109156 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.030044  [    0/   75]\n",
      "Test avg loss: 0.098391 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.030230  [    0/   75]\n",
      "Test avg loss: 0.099304 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.029236  [    0/   75]\n",
      "Test avg loss: 0.117694 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.031155  [    0/   75]\n",
      "Test avg loss: 0.100483 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.030383  [    0/   75]\n",
      "Test avg loss: 0.105265 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.029904  [    0/   75]\n",
      "Test avg loss: 0.082172 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.030575  [    0/   75]\n",
      "Test avg loss: 0.087775 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.029340  [    0/   75]\n",
      "Test avg loss: 0.103518 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.030756  [    0/   75]\n",
      "Test avg loss: 0.084107 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.030211  [    0/   75]\n",
      "Test avg loss: 0.079756 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.030871  [    0/   75]\n",
      "Test avg loss: 0.104762 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.029934  [    0/   75]\n",
      "Test avg loss: 0.086798 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.030075  [    0/   75]\n",
      "Test avg loss: 0.119157 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.028303  [    0/   75]\n",
      "Test avg loss: 0.085328 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.029515  [    0/   75]\n",
      "Test avg loss: 0.113515 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.030244  [    0/   75]\n",
      "Test avg loss: 0.104870 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.030526  [    0/   75]\n",
      "Test avg loss: 0.109192 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.030669  [    0/   75]\n",
      "Test avg loss: 0.087956 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.030626  [    0/   75]\n",
      "Test avg loss: 0.112144 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.028557  [    0/   75]\n",
      "Test avg loss: 0.087595 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.029361  [    0/   75]\n",
      "Test avg loss: 0.094921 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.030612  [    0/   75]\n",
      "Test avg loss: 0.123978 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.031171  [    0/   75]\n",
      "Test avg loss: 0.100450 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.030780  [    0/   75]\n",
      "Test avg loss: 0.088060 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.028912  [    0/   75]\n",
      "Test avg loss: 0.099144 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.030067  [    0/   75]\n",
      "Test avg loss: 0.117377 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.029799  [    0/   75]\n",
      "Test avg loss: 0.107595 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.030036  [    0/   75]\n",
      "Test avg loss: 0.091543 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.030063  [    0/   75]\n",
      "Test avg loss: 0.112950 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.028938  [    0/   75]\n",
      "Test avg loss: 0.082905 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.030449  [    0/   75]\n",
      "Test avg loss: 0.104377 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.030954  [    0/   75]\n",
      "Test avg loss: 0.097415 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.028428  [    0/   75]\n",
      "Test avg loss: 0.083471 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.028088  [    0/   75]\n",
      "Test avg loss: 0.092028 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.030169  [    0/   75]\n",
      "Test avg loss: 0.089848 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.029781  [    0/   75]\n",
      "Test avg loss: 0.110636 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.030584  [    0/   75]\n",
      "Test avg loss: 0.078625 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.030115  [    0/   75]\n",
      "Test avg loss: 0.079665 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.030721  [    0/   75]\n",
      "Test avg loss: 0.106414 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.030027  [    0/   75]\n",
      "Test avg loss: 0.092890 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.030038  [    0/   75]\n",
      "Test avg loss: 0.110515 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.030178  [    0/   75]\n",
      "Test avg loss: 0.114277 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.030384  [    0/   75]\n",
      "Test avg loss: 0.109271 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.028982  [    0/   75]\n",
      "Test avg loss: 0.102971 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.030439  [    0/   75]\n",
      "Test avg loss: 0.110768 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.029502  [    0/   75]\n",
      "Test avg loss: 0.122408 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.030382  [    0/   75]\n",
      "Test avg loss: 0.084948 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.029849  [    0/   75]\n",
      "Test avg loss: 0.103476 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.029864  [    0/   75]\n",
      "Test avg loss: 0.094009 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.030455  [    0/   75]\n",
      "Test avg loss: 0.101563 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.030303  [    0/   75]\n",
      "Test avg loss: 0.094246 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.029666  [    0/   75]\n",
      "Test avg loss: 0.104969 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.029370  [    0/   75]\n",
      "Test avg loss: 0.083551 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.030209  [    0/   75]\n",
      "Test avg loss: 0.091933 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.027540  [    0/   75]\n",
      "Test avg loss: 0.099034 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.031124  [    0/   75]\n",
      "Test avg loss: 0.116163 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.030346  [    0/   75]\n",
      "Test avg loss: 0.089953 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.028470  [    0/   75]\n",
      "Test avg loss: 0.120763 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.030485  [    0/   75]\n",
      "Test avg loss: 0.091676 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.027954  [    0/   75]\n",
      "Test avg loss: 0.103772 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.028800  [    0/   75]\n",
      "Test avg loss: 0.104779 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.029371  [    0/   75]\n",
      "Test avg loss: 0.080661 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.030692  [    0/   75]\n",
      "Test avg loss: 0.106995 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.028496  [    0/   75]\n",
      "Test avg loss: 0.097120 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.029261  [    0/   75]\n",
      "Test avg loss: 0.083219 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.030953  [    0/   75]\n",
      "Test avg loss: 0.079679 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.029513  [    0/   75]\n",
      "Test avg loss: 0.115316 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.031245  [    0/   75]\n",
      "Test avg loss: 0.091961 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.028719  [    0/   75]\n",
      "Test avg loss: 0.082239 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.029444  [    0/   75]\n",
      "Test avg loss: 0.074893 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.030629  [    0/   75]\n",
      "Test avg loss: 0.102659 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.030454  [    0/   75]\n",
      "Test avg loss: 0.099267 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.031080  [    0/   75]\n",
      "Test avg loss: 0.110208 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.028626  [    0/   75]\n",
      "Test avg loss: 0.079530 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.030735  [    0/   75]\n",
      "Test avg loss: 0.094663 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.028210  [    0/   75]\n",
      "Test avg loss: 0.088306 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.029348  [    0/   75]\n",
      "Test avg loss: 0.124524 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.028799  [    0/   75]\n",
      "Test avg loss: 0.112677 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.030902  [    0/   75]\n",
      "Test avg loss: 0.115293 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.030544  [    0/   75]\n",
      "Test avg loss: 0.080594 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.028456  [    0/   75]\n",
      "Test avg loss: 0.079395 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.030787  [    0/   75]\n",
      "Test avg loss: 0.101805 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.030223  [    0/   75]\n",
      "Test avg loss: 0.098123 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.029195  [    0/   75]\n",
      "Test avg loss: 0.097564 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.030597  [    0/   75]\n",
      "Test avg loss: 0.079894 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.029363  [    0/   75]\n",
      "Test avg loss: 0.096223 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.030123  [    0/   75]\n",
      "Test avg loss: 0.104971 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.028413  [    0/   75]\n",
      "Test avg loss: 0.086175 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.030520  [    0/   75]\n",
      "Test avg loss: 0.127152 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.030399  [    0/   75]\n",
      "Test avg loss: 0.114055 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.030418  [    0/   75]\n",
      "Test avg loss: 0.093158 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.030353  [    0/   75]\n",
      "Test avg loss: 0.109432 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.028698  [    0/   75]\n",
      "Test avg loss: 0.077115 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.030969  [    0/   75]\n",
      "Test avg loss: 0.106309 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.027902  [    0/   75]\n",
      "Test avg loss: 0.115996 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.030131  [    0/   75]\n",
      "Test avg loss: 0.081667 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.030530  [    0/   75]\n",
      "Test avg loss: 0.076212 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.029773  [    0/   75]\n",
      "Test avg loss: 0.083031 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.026909  [    0/   75]\n",
      "Test avg loss: 0.088928 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.030096  [    0/   75]\n",
      "Test avg loss: 0.084971 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.029816  [    0/   75]\n",
      "Test avg loss: 0.099738 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.029220  [    0/   75]\n",
      "Test avg loss: 0.103548 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.029872  [    0/   75]\n",
      "Test avg loss: 0.114320 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.030760  [    0/   75]\n",
      "Test avg loss: 0.095179 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.030629  [    0/   75]\n",
      "Test avg loss: 0.122852 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.029827  [    0/   75]\n",
      "Test avg loss: 0.104763 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.030133  [    0/   75]\n",
      "Test avg loss: 0.090413 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.027661  [    0/   75]\n",
      "Test avg loss: 0.095389 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.029960  [    0/   75]\n",
      "Test avg loss: 0.101863 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.029683  [    0/   75]\n",
      "Test avg loss: 0.110085 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.028884  [    0/   75]\n",
      "Test avg loss: 0.075571 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.028729  [    0/   75]\n",
      "Test avg loss: 0.094660 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.029934  [    0/   75]\n",
      "Test avg loss: 0.113387 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.030637  [    0/   75]\n",
      "Test avg loss: 0.081518 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.028742  [    0/   75]\n",
      "Test avg loss: 0.093202 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.028700  [    0/   75]\n",
      "Test avg loss: 0.077360 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.029799  [    0/   75]\n",
      "Test avg loss: 0.107681 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.030796  [    0/   75]\n",
      "Test avg loss: 0.078296 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.030517  [    0/   75]\n",
      "Test avg loss: 0.096545 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.030328  [    0/   75]\n",
      "Test avg loss: 0.101263 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.029997  [    0/   75]\n",
      "Test avg loss: 0.094646 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.029841  [    0/   75]\n",
      "Test avg loss: 0.113814 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.029124  [    0/   75]\n",
      "Test avg loss: 0.100061 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.029150  [    0/   75]\n",
      "Test avg loss: 0.109527 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.030603  [    0/   75]\n",
      "Test avg loss: 0.092634 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.030783  [    0/   75]\n",
      "Test avg loss: 0.085633 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.030111  [    0/   75]\n",
      "Test avg loss: 0.078596 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.029944  [    0/   75]\n",
      "Test avg loss: 0.076464 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.030785  [    0/   75]\n",
      "Test avg loss: 0.098072 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.028122  [    0/   75]\n",
      "Test avg loss: 0.088728 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.030049  [    0/   75]\n",
      "Test avg loss: 0.103996 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.030277  [    0/   75]\n",
      "Test avg loss: 0.122212 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.030648  [    0/   75]\n",
      "Test avg loss: 0.119014 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.031279  [    0/   75]\n",
      "Test avg loss: 0.106010 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.028522  [    0/   75]\n",
      "Test avg loss: 0.098178 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.030782  [    0/   75]\n",
      "Test avg loss: 0.127436 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.030137  [    0/   75]\n",
      "Test avg loss: 0.078628 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.029126  [    0/   75]\n",
      "Test avg loss: 0.079028 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.031068  [    0/   75]\n",
      "Test avg loss: 0.098011 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.030951  [    0/   75]\n",
      "Test avg loss: 0.100106 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.030745  [    0/   75]\n",
      "Test avg loss: 0.109319 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.031003  [    0/   75]\n",
      "Test avg loss: 0.090026 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.029692  [    0/   75]\n",
      "Test avg loss: 0.079372 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.029822  [    0/   75]\n",
      "Test avg loss: 0.120838 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.030628  [    0/   75]\n",
      "Test avg loss: 0.095668 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.030373  [    0/   75]\n",
      "Test avg loss: 0.107267 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.029413  [    0/   75]\n",
      "Test avg loss: 0.082177 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.030615  [    0/   75]\n",
      "Test avg loss: 0.096602 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.030791  [    0/   75]\n",
      "Test avg loss: 0.086210 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.030106  [    0/   75]\n",
      "Test avg loss: 0.096821 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.029923  [    0/   75]\n",
      "Test avg loss: 0.102630 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.030629  [    0/   75]\n",
      "Test avg loss: 0.116583 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.030204  [    0/   75]\n",
      "Test avg loss: 0.085903 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.028677  [    0/   75]\n",
      "Test avg loss: 0.086385 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.030027  [    0/   75]\n",
      "Test avg loss: 0.112656 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.029329  [    0/   75]\n",
      "Test avg loss: 0.112974 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.028047  [    0/   75]\n",
      "Test avg loss: 0.080354 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.029107  [    0/   75]\n",
      "Test avg loss: 0.090530 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.030323  [    0/   75]\n",
      "Test avg loss: 0.106209 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.030660  [    0/   75]\n",
      "Test avg loss: 0.105734 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.029007  [    0/   75]\n",
      "Test avg loss: 0.131694 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.029275  [    0/   75]\n",
      "Test avg loss: 0.093611 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.028902  [    0/   75]\n",
      "Test avg loss: 0.117559 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.029298  [    0/   75]\n",
      "Test avg loss: 0.095335 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.029832  [    0/   75]\n",
      "Test avg loss: 0.114435 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.030530  [    0/   75]\n",
      "Test avg loss: 0.106335 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.030310  [    0/   75]\n",
      "Test avg loss: 0.116979 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.030288  [    0/   75]\n",
      "Test avg loss: 0.115510 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.028462  [    0/   75]\n",
      "Test avg loss: 0.078917 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.029955  [    0/   75]\n",
      "Test avg loss: 0.097221 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.030084  [    0/   75]\n",
      "Test avg loss: 0.101111 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.030556  [    0/   75]\n",
      "Test avg loss: 0.112711 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.028153  [    0/   75]\n",
      "Test avg loss: 0.092558 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.029249  [    0/   75]\n",
      "Test avg loss: 0.097261 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.030627  [    0/   75]\n",
      "Test avg loss: 0.119069 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.030689  [    0/   75]\n",
      "Test avg loss: 0.122719 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.030014  [    0/   75]\n",
      "Test avg loss: 0.073134 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.030672  [    0/   75]\n",
      "Test avg loss: 0.129360 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.028985  [    0/   75]\n",
      "Test avg loss: 0.079014 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.028473  [    0/   75]\n",
      "Test avg loss: 0.100251 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.029759  [    0/   75]\n",
      "Test avg loss: 0.081238 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.030220  [    0/   75]\n",
      "Test avg loss: 0.098755 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.030705  [    0/   75]\n",
      "Test avg loss: 0.094808 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.028389  [    0/   75]\n",
      "Test avg loss: 0.108246 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.030584  [    0/   75]\n",
      "Test avg loss: 0.109966 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.030702  [    0/   75]\n",
      "Test avg loss: 0.089367 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.028563  [    0/   75]\n",
      "Test avg loss: 0.092717 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.028854  [    0/   75]\n",
      "Test avg loss: 0.099391 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.029141  [    0/   75]\n",
      "Test avg loss: 0.083463 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.028671  [    0/   75]\n",
      "Test avg loss: 0.077658 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.030576  [    0/   75]\n",
      "Test avg loss: 0.103850 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.028313  [    0/   75]\n",
      "Test avg loss: 0.104104 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.030746  [    0/   75]\n",
      "Test avg loss: 0.082575 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.030530  [    0/   75]\n",
      "Test avg loss: 0.099431 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.030190  [    0/   75]\n",
      "Test avg loss: 0.091414 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.030698  [    0/   75]\n",
      "Test avg loss: 0.115836 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.028124  [    0/   75]\n",
      "Test avg loss: 0.097312 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.030539  [    0/   75]\n",
      "Test avg loss: 0.074592 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.029862  [    0/   75]\n",
      "Test avg loss: 0.124453 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.029258  [    0/   75]\n",
      "Test avg loss: 0.086039 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.030932  [    0/   75]\n",
      "Test avg loss: 0.098143 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.030359  [    0/   75]\n",
      "Test avg loss: 0.132325 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.030326  [    0/   75]\n",
      "Test avg loss: 0.087452 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.029497  [    0/   75]\n",
      "Test avg loss: 0.085369 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.029965  [    0/   75]\n",
      "Test avg loss: 0.073835 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.029989  [    0/   75]\n",
      "Test avg loss: 0.105286 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.029895  [    0/   75]\n",
      "Test avg loss: 0.085071 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.029772  [    0/   75]\n",
      "Test avg loss: 0.103110 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.030175  [    0/   75]\n",
      "Test avg loss: 0.128963 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.030241  [    0/   75]\n",
      "Test avg loss: 0.074577 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.028448  [    0/   75]\n",
      "Test avg loss: 0.103998 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.030166  [    0/   75]\n",
      "Test avg loss: 0.085488 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.030702  [    0/   75]\n",
      "Test avg loss: 0.102067 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.029419  [    0/   75]\n",
      "Test avg loss: 0.098412 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.030882  [    0/   75]\n",
      "Test avg loss: 0.101407 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.027853  [    0/   75]\n",
      "Test avg loss: 0.109183 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.029926  [    0/   75]\n",
      "Test avg loss: 0.098223 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.030375  [    0/   75]\n",
      "Test avg loss: 0.099454 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.029502  [    0/   75]\n",
      "Test avg loss: 0.086457 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.030268  [    0/   75]\n",
      "Test avg loss: 0.093374 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.031203  [    0/   75]\n",
      "Test avg loss: 0.107756 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.028716  [    0/   75]\n",
      "Test avg loss: 0.106489 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.029650  [    0/   75]\n",
      "Test avg loss: 0.094441 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.030027  [    0/   75]\n",
      "Test avg loss: 0.117861 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.029278  [    0/   75]\n",
      "Test avg loss: 0.096195 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.029846  [    0/   75]\n",
      "Test avg loss: 0.089308 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.029168  [    0/   75]\n",
      "Test avg loss: 0.079736 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.029077  [    0/   75]\n",
      "Test avg loss: 0.090585 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.030882  [    0/   75]\n",
      "Test avg loss: 0.074478 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.029193  [    0/   75]\n",
      "Test avg loss: 0.084046 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.029641  [    0/   75]\n",
      "Test avg loss: 0.097775 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.030504  [    0/   75]\n",
      "Test avg loss: 0.092939 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.030438  [    0/   75]\n",
      "Test avg loss: 0.115683 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.028604  [    0/   75]\n",
      "Test avg loss: 0.103970 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.030385  [    0/   75]\n",
      "Test avg loss: 0.083619 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.030061  [    0/   75]\n",
      "Test avg loss: 0.085923 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.030196  [    0/   75]\n",
      "Test avg loss: 0.098028 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.030337  [    0/   75]\n",
      "Test avg loss: 0.110024 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.029205  [    0/   75]\n",
      "Test avg loss: 0.099625 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.031116  [    0/   75]\n",
      "Test avg loss: 0.081732 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.031029  [    0/   75]\n",
      "Test avg loss: 0.108814 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.030692  [    0/   75]\n",
      "Test avg loss: 0.079878 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.028629  [    0/   75]\n",
      "Test avg loss: 0.093300 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.030061  [    0/   75]\n",
      "Test avg loss: 0.130061 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.030092  [    0/   75]\n",
      "Test avg loss: 0.092475 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.029798  [    0/   75]\n",
      "Test avg loss: 0.082102 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.030665  [    0/   75]\n",
      "Test avg loss: 0.099103 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.030240  [    0/   75]\n",
      "Test avg loss: 0.102852 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.027682  [    0/   75]\n",
      "Test avg loss: 0.115534 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.029592  [    0/   75]\n",
      "Test avg loss: 0.076765 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.030093  [    0/   75]\n",
      "Test avg loss: 0.084913 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.028645  [    0/   75]\n",
      "Test avg loss: 0.073100 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.029974  [    0/   75]\n",
      "Test avg loss: 0.127646 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.028844  [    0/   75]\n",
      "Test avg loss: 0.111839 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.030966  [    0/   75]\n",
      "Test avg loss: 0.081543 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.028972  [    0/   75]\n",
      "Test avg loss: 0.098743 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.030383  [    0/   75]\n",
      "Test avg loss: 0.081271 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.029064  [    0/   75]\n",
      "Test avg loss: 0.080324 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.029245  [    0/   75]\n",
      "Test avg loss: 0.103834 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.029758  [    0/   75]\n",
      "Test avg loss: 0.126877 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.028845  [    0/   75]\n",
      "Test avg loss: 0.121433 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.029749  [    0/   75]\n",
      "Test avg loss: 0.083424 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.030327  [    0/   75]\n",
      "Test avg loss: 0.077144 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.029832  [    0/   75]\n",
      "Test avg loss: 0.080715 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.030807  [    0/   75]\n",
      "Test avg loss: 0.077870 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.028647  [    0/   75]\n",
      "Test avg loss: 0.095112 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.030830  [    0/   75]\n",
      "Test avg loss: 0.085305 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.030837  [    0/   75]\n",
      "Test avg loss: 0.078537 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.030110  [    0/   75]\n",
      "Test avg loss: 0.106039 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.028754  [    0/   75]\n",
      "Test avg loss: 0.074771 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.029757  [    0/   75]\n",
      "Test avg loss: 0.099490 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.030071  [    0/   75]\n",
      "Test avg loss: 0.108445 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.030285  [    0/   75]\n",
      "Test avg loss: 0.088429 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.027896  [    0/   75]\n",
      "Test avg loss: 0.079118 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.030849  [    0/   75]\n",
      "Test avg loss: 0.104870 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.030099  [    0/   75]\n",
      "Test avg loss: 0.094456 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.029862  [    0/   75]\n",
      "Test avg loss: 0.081679 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.030133  [    0/   75]\n",
      "Test avg loss: 0.108396 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_loader)\n",
    "    test_loop(dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df60aeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16975a6a0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epch = np.arange(epochs)\n",
    "plt.plot(epch,train_loss)\n",
    "plt.plot(epch,val_loss)\n",
    "# plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc27282b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
